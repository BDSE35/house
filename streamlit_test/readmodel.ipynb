{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LSTM' from 'my_models' (c:\\Users\\student\\Desktop\\house\\streamlit_test\\my_models.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmy_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSTM\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'LSTM' from 'my_models' (c:\\Users\\student\\Desktop\\house\\streamlit_test\\my_models.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from my_models import LSTMModel  # Import the model class from the original script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\AppData\\Local\\Temp\\ipykernel_10916\\3036330405.py:2: DtypeWarning: Columns (37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"房價_add南科and股價 (1).csv\")\n"
     ]
    }
   ],
   "source": [
    "# Load your CSV file (make sure it has the same features used in training)\n",
    "df = pd.read_csv(\"房價_add南科and股價 (1).csv\")\n",
    "\n",
    "# Ensure the data is sorted and preprocessed similarly\n",
    "df[\"交易年月日\"] = pd.to_datetime(df[\"交易年月日\"])\n",
    "df = df.sort_values(\"交易年月日\")\n",
    "\n",
    "# Your numerical and one-hot feature columns\n",
    "numerical_features =[\n",
    "    \"單價元每坪\",\n",
    "    \"建物移轉總面積平方公尺\",\n",
    "    # \"time_diff\",\n",
    "    # \"cumulative_time\",\n",
    "    \"建物現況格局-房\",\n",
    "    \"建物現況格局-廳\",\n",
    "    \"建物現況格局-衛\",\n",
    "    \"建物現況格局-隔間\",\n",
    "    \"屋齡\",\n",
    "    # \"營業額總計\",\n",
    "    \"stockTW\",\n",
    "    \"KDE_0.5km\",\n",
    "    \"KDE_1km\",\n",
    "    \"KDE_1.5km\",\n",
    "    # \"KDE_class\",\n",
    "    \"good_count_0_500\",\n",
    "    \"good_count_500_1000\",\n",
    "    \"good_count_1000_1500\",\n",
    "    \"bad_count_0_500\",\n",
    "    \"bad_count_500_1000\",\n",
    "    \"bad_count_1000_1500\",\n",
    "]\n",
    "one_hot_features = [\n",
    "    \"建築型態_住商大樓\",\n",
    "    \"建築型態_公寓\",\n",
    "    \"建築型態_其他\",\n",
    "    \"建築型態_透天厝\",\n",
    "    \"是否包含車位\",\n",
    "    \"建材_磚石\",\n",
    "    \"建材_鋼筋\",\n",
    "    \"建材_鋼骨\",\n",
    "    \"建材_竹木\",\n",
    "    \"住\",\n",
    "    \"商\",\n",
    "    \"工\",\n",
    "    \"農\",\n",
    "    \"移轉層次_騎樓\",\n",
    "    \"移轉層次_屋頂\",\n",
    "    \"移轉層次_一二樓\",\n",
    "    \"鄉鎮_七股區\",\n",
    "    \"鄉鎮_下營區\",\n",
    "    \"鄉鎮_中西區\",\n",
    "    \"鄉鎮_仁德區\",\n",
    "    \"鄉鎮_佳里區\",\n",
    "    \"鄉鎮_六甲區\",\n",
    "    \"鄉鎮_北區\",\n",
    "    \"鄉鎮_北門區\",\n",
    "    \"鄉鎮_南化區\",\n",
    "    \"鄉鎮_南區\",\n",
    "    \"鄉鎮_善化區\",\n",
    "    \"鄉鎮_大內區\",\n",
    "    \"鄉鎮_學甲區\",\n",
    "    \"鄉鎮_安南區\",\n",
    "    \"鄉鎮_安定區\",\n",
    "    \"鄉鎮_安平區\",\n",
    "    \"鄉鎮_官田區\",\n",
    "    \"鄉鎮_將軍區\",\n",
    "    \"鄉鎮_山上區\",\n",
    "    \"鄉鎮_左鎮區\",\n",
    "    \"鄉鎮_後壁區\",\n",
    "    \"鄉鎮_新化區\",\n",
    "    \"鄉鎮_新市區\",\n",
    "    \"鄉鎮_新營區\",\n",
    "    \"鄉鎮_東區\",\n",
    "    \"鄉鎮_東山區\",\n",
    "    \"鄉鎮_柳營區\",\n",
    "    \"鄉鎮_楠西區\",\n",
    "    \"鄉鎮_歸仁區\",\n",
    "    \"鄉鎮_永康區\",\n",
    "    \"鄉鎮_玉井區\",\n",
    "    \"鄉鎮_白河區\",\n",
    "    \"鄉鎮_西港區\",\n",
    "    \"鄉鎮_關廟區\",\n",
    "    \"鄉鎮_鹽水區\",\n",
    "    \"鄉鎮_麻豆區\",\n",
    "    \"鄉鎮_龍崎區\",\n",
    "]\n",
    "\n",
    "# 目標變數\n",
    "target_feature = [\"單價元每坪\"]\n",
    "\n",
    "# Extract features\n",
    "numerical_data = df[numerical_features].values\n",
    "one_hot_data = df[one_hot_features].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "numerical_tensor = torch.FloatTensor(numerical_data)\n",
    "one_hot_tensor = torch.FloatTensor(one_hot_data)\n",
    "\n",
    "# Combine numerical and one-hot features\n",
    "X = np.hstack([numerical_data, one_hot_data])\n",
    "X_tensor = torch.FloatTensor(X)\n",
    "X_tensor = X_tensor.unsqueeze(1)  # Add an extra dimension if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\AppData\\Local\\Temp\\ipykernel_10916\\188705061.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(\"LSTM_model1101.pth\")\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'LSTM' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLSTM_model1101.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\student\\anaconda3\\envs\\web_scraping\\lib\\site-packages\\torch\\serialization.py:1097\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1095\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1096\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1097\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[0;32m   1098\u001b[0m             opened_zipfile,\n\u001b[0;32m   1099\u001b[0m             map_location,\n\u001b[0;32m   1100\u001b[0m             pickle_module,\n\u001b[0;32m   1101\u001b[0m             overall_storage\u001b[38;5;241m=\u001b[39moverall_storage,\n\u001b[0;32m   1102\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args,\n\u001b[0;32m   1103\u001b[0m         )\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[0;32m   1105\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\student\\anaconda3\\envs\\web_scraping\\lib\\site-packages\\torch\\serialization.py:1525\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# Needed for tensors where storage device and rebuild tensor device are\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# not connected (wrapper subclasses and tensors rebuilt using numpy)\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_thread_local_state\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m map_location\n\u001b[1;32m-> 1525\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_thread_local_state\u001b[38;5;241m.\u001b[39mmap_location\n\u001b[0;32m   1528\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n",
      "File \u001b[1;32mc:\\Users\\student\\anaconda3\\envs\\web_scraping\\lib\\site-packages\\torch\\serialization.py:1515\u001b[0m, in \u001b[0;36m_load.<locals>.UnpicklerWrapper.find_class\u001b[1;34m(self, mod_name, name)\u001b[0m\n\u001b[0;32m   1513\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m mod_name \u001b[38;5;241m=\u001b[39m load_module_mapping\u001b[38;5;241m.\u001b[39mget(mod_name, mod_name)\n\u001b[1;32m-> 1515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute 'LSTM' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"LSTM_model1101.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\AppData\\Local\\Temp\\ipykernel_10916\\1747219817.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"LSTM_model1101.pth\"))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'LSTM' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 13\u001b[0m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m LSTMModel(\n\u001b[0;32m      5\u001b[0m     input_dim\u001b[38;5;241m=\u001b[39mX_tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m],  \u001b[38;5;66;03m# Number of features\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,  \u001b[38;5;66;03m# As used during training\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m     dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m\n\u001b[0;32m     10\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Load the model weights\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLSTM_model1101.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[1;32mc:\\Users\\student\\anaconda3\\envs\\web_scraping\\lib\\site-packages\\torch\\serialization.py:1097\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1095\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1096\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1097\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[0;32m   1098\u001b[0m             opened_zipfile,\n\u001b[0;32m   1099\u001b[0m             map_location,\n\u001b[0;32m   1100\u001b[0m             pickle_module,\n\u001b[0;32m   1101\u001b[0m             overall_storage\u001b[38;5;241m=\u001b[39moverall_storage,\n\u001b[0;32m   1102\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args,\n\u001b[0;32m   1103\u001b[0m         )\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[0;32m   1105\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\student\\anaconda3\\envs\\web_scraping\\lib\\site-packages\\torch\\serialization.py:1525\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# Needed for tensors where storage device and rebuild tensor device are\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# not connected (wrapper subclasses and tensors rebuilt using numpy)\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_thread_local_state\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m map_location\n\u001b[1;32m-> 1525\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_thread_local_state\u001b[38;5;241m.\u001b[39mmap_location\n\u001b[0;32m   1528\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n",
      "File \u001b[1;32mc:\\Users\\student\\anaconda3\\envs\\web_scraping\\lib\\site-packages\\torch\\serialization.py:1515\u001b[0m, in \u001b[0;36m_load.<locals>.UnpicklerWrapper.find_class\u001b[1;34m(self, mod_name, name)\u001b[0m\n\u001b[0;32m   1513\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m mod_name \u001b[38;5;241m=\u001b[39m load_module_mapping\u001b[38;5;241m.\u001b[39mget(mod_name, mod_name)\n\u001b[1;32m-> 1515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute 'LSTM' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the model with the same parameters used for training\n",
    "model = LSTMModel(\n",
    "    input_dim=X_tensor.shape[2],  # Number of features\n",
    "    hidden_dim=64,  # As used during training\n",
    "    num_layers=2,\n",
    "    output_dim=1,\n",
    "    dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "# Load the model weights\n",
    "model.load_state_dict(torch.load(\"LSTM_model1101.pth\"))\n",
    "model.eval()  # Set the model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    predictions = model(X_tensor.to(device))\n",
    "    predictions = predictions.cpu().numpy()  # Convert to NumPy array\n",
    "\n",
    "\n",
    "df[\"Predicted_Unit_Price\"] = predictions\n",
    "df.to_csv(\"updated_data_with_predictions.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web_scraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
